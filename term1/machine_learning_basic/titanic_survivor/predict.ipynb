{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    701\n",
      "0    190\n",
      "Name: Result, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "train[\"Hyp\"] = 0\n",
    "train.loc[train.Sex == 'female', \"Hyp\"] = 1\n",
    "\n",
    "train[\"Result\"] = 0\n",
    "train.loc[train.Survived == train[\"Hyp\"], \"Result\"] = 1\n",
    "\n",
    "print(train[\"Result\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793490460157\n",
      "0.830527497194\n"
     ]
    }
   ],
   "source": [
    "#使用logistic回归进行预测，仅在训练集上对比\n",
    "#没有特别考虑性别权重\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, preprocessing\n",
    "\n",
    "def clean_data(data):\n",
    "    data[\"Fare\"] = data[\"Fare\"].fillna(data[\"Fare\"].dropna().median()) #用非空中值填补空的票价\n",
    "    data[\"Age\"] = data[\"Age\"].fillna(data[\"Age\"].dropna().median())\n",
    "    \n",
    "    data.loc[data[\"Sex\"] == \"male\", \"Sex\"] = 0 #数值化性别\n",
    "    data.loc[data[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "    \n",
    "    data[\"Embarked\"] = data[\"Embarked\"].fillna(\"S\") #用S填补空的登船地点\n",
    "    data.loc[data[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "    data.loc[data[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "    data.loc[data[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "clean_data(train)\n",
    "feature_names = [\"Pclass\", \"Age\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "\n",
    "target = train[\"Survived\"].values\n",
    "features = train[feature_names].values\n",
    "classifier = linear_model.LogisticRegression()\n",
    "classifier_ = classifier.fit(features, target)\n",
    "print(classifier_.score(features, target))\n",
    "\n",
    "'''Generate polynomial and interaction features.\n",
    "Generate a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. \n",
    "For example, if an input sample is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].\n",
    "'''\n",
    "poly = preprocessing.PolynomialFeatures(degree=2) #创造更多特征，补充2次型\n",
    "poly_features = poly.fit_transform(features)\n",
    "\n",
    "classifier_ = classifier.fit(poly_features, target)\n",
    "print(classifier_.score(poly_features, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策数得分： 0.916947250281\n",
      "scores: [ 0.77777778  0.72222222  0.77777778  0.88888889  0.77777778  0.77777778\n",
      "  0.61111111  0.77777778  0.77777778  0.88888889  0.77777778  0.72222222\n",
      "  0.77777778  0.77777778  0.77777778  0.77777778  0.94444444  0.83333333\n",
      "  0.83333333  0.88888889  0.94444444  0.72222222  0.83333333  0.77777778\n",
      "  0.72222222  0.83333333  0.83333333  0.88888889  0.55555556  0.83333333\n",
      "  0.77777778  0.66666667  0.88888889  0.94444444  0.83333333  0.72222222\n",
      "  0.66666667  0.72222222  0.83333333  0.88888889  0.88888889  0.83333333\n",
      "  0.76470588  0.76470588  0.94117647  0.76470588  0.82352941  0.82352941\n",
      "  0.82352941  0.875     ]\n",
      "avg scores: 0.801617647059\n",
      "==========================================\n",
      "决策数得分： 0.852974186308\n",
      "scores: [ 0.88888889  0.72222222  0.77777778  0.94444444  0.72222222  0.83333333\n",
      "  0.55555556  0.77777778  0.77777778  0.94444444  0.83333333  0.77777778\n",
      "  0.83333333  0.77777778  0.66666667  0.66666667  0.94444444  0.77777778\n",
      "  0.88888889  0.94444444  0.94444444  0.72222222  0.77777778  0.77777778\n",
      "  0.77777778  0.77777778  0.83333333  0.83333333  0.61111111  0.88888889\n",
      "  0.72222222  0.72222222  0.83333333  0.83333333  0.88888889  0.77777778\n",
      "  0.72222222  0.77777778  0.77777778  0.77777778  0.83333333  0.88888889\n",
      "  0.76470588  0.88235294  0.76470588  0.76470588  0.76470588  0.82352941\n",
      "  1.          0.875     ]\n",
      "avg scores: 0.803905228758\n"
     ]
    }
   ],
   "source": [
    "#使用决策树预测，仅在训练集上对比\n",
    "#性别没有特殊权重\n",
    "import pandas as pd\n",
    "from sklearn import tree, model_selection\n",
    "import numpy as np\n",
    "\n",
    "def clean_data(data):\n",
    "    data[\"Fare\"] = data[\"Fare\"].fillna(data[\"Fare\"].dropna().median()) #用非空中值填补空的票价\n",
    "    data[\"Age\"] = data[\"Age\"].fillna(data[\"Age\"].dropna().median())\n",
    "    \n",
    "    data.loc[data[\"Sex\"] == \"male\", \"Sex\"] = 0 #数值化性别\n",
    "    data.loc[data[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "    \n",
    "    data[\"Embarked\"] = data[\"Embarked\"].fillna(\"S\") #用S填补空的登船地点\n",
    "    data.loc[data[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "    data.loc[data[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "    data.loc[data[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "def write_prediction(prediction, name):\n",
    "    PassengerId = np.array(test[\"PassengerId\"]).astype(int)\n",
    "    solution = pd.DataFrame(prediction, PassengerId, columns = [\"Survived\"])\n",
    "    solution.to_csv(name, index_label = [\"PassengerId\"])\n",
    "\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "clean_data(train)\n",
    "feature_names = [\"Pclass\", \"Age\", \"Sex\", \"SibSp\", \"Parch\"]\n",
    "\n",
    "target = train[\"Survived\"].values\n",
    "features = train[feature_names].values\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier(random_state = 1)\n",
    "decision_tree_ = decision_tree.fit(features,target)\n",
    "\n",
    "print(\"决策数得分：\",decision_tree_.score(features,target))\n",
    "#验证某个模型在某个训练集上的稳定性，输出k个预测精度。\n",
    "scores = model_selection.cross_val_score(decision_tree, features, target, scoring='accuracy',cv=50)\n",
    "print(\"scores:\",scores)\n",
    "print(\"avg scores:\",scores.mean())\n",
    "\n",
    "print(\"==========================================\")\n",
    "#防止过拟合？\n",
    "generalized_tree = tree.DecisionTreeClassifier(\n",
    "    random_state = 1,\n",
    "    max_depth = 7,\n",
    "    min_samples_split = 2)\n",
    "generalized_tree_ = generalized_tree.fit(features,target)\n",
    "print(\"决策数得分：\",generalized_tree_.score(features,target))\n",
    "scores = model_selection.cross_val_score(generalized_tree, features, target, scoring='accuracy',cv=50)\n",
    "print(\"scores:\",scores)\n",
    "print(\"avg scores:\",scores.mean())\n",
    "\n",
    "tree.export_graphviz(generalized_tree_,feature_names=feature_names, out_file=\"tree.dot\")\n",
    "\n",
    "\n",
    "#输出预测结果\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "clean_data(test)\n",
    "test_features_two = test[feature_names].values\n",
    "prediction_two = generalized_tree_.predict(test_features_two)\n",
    "write_prediction(prediction_two, \"decision_tree_two.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning up some data\n",
      "\n",
      "Extracting target and features\n",
      "(891, 12)\n",
      "\n",
      "Use gradient boosting classifier\n",
      "[mean: 0.87306, std: 0.04514, params: {'n_estimators': 140}, mean: 0.87388, std: 0.04394, params: {'n_estimators': 280}, mean: 0.87483, std: 0.04443, params: {'n_estimators': 560}, mean: 0.87585, std: 0.04575, params: {'n_estimators': 1120}, mean: 0.87516, std: 0.05115, params: {'n_estimators': 4480}] {'n_estimators': 1120} 0.875848456554339\n",
      "[ 0.05732547  0.32300303  0.11482147  0.36183847  0.05657822  0.04783569\n",
      "  0.03859766]\n",
      "0.94051627385\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import ensemble, model_selection, grid_search\n",
    "\n",
    "def clean_data(data):\n",
    "    data[\"Fare\"] = data[\"Fare\"].fillna(data[\"Fare\"].dropna().median()) #用非空中值填补空的票价\n",
    "    data[\"Age\"] = data[\"Age\"].fillna(data[\"Age\"].dropna().median())\n",
    "    \n",
    "    data.loc[data[\"Sex\"] == \"male\", \"Sex\"] = 0 #数值化性别\n",
    "    data.loc[data[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "    \n",
    "    data[\"Embarked\"] = data[\"Embarked\"].fillna(\"S\") #用S填补空的登船地点\n",
    "    data.loc[data[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "    data.loc[data[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "    data.loc[data[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "def write_prediction(prediction, name):\n",
    "    PassengerId = np.array(test[\"PassengerId\"]).astype(int)\n",
    "    solution = pd.DataFrame(prediction, PassengerId, columns = [\"Survived\"])\n",
    "    solution.to_csv(name, index_label = [\"PassengerId\"])\n",
    "\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "print(\"\\nCleaning up some data\")\n",
    "\n",
    "clean_data(train)\n",
    "clean_data(test)\n",
    "\n",
    "print(\"\\nExtracting target and features\")\n",
    "\n",
    "print(train.shape)\n",
    "target = train[\"Survived\"].values\n",
    "features = train[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "\n",
    "print(\"\\nUse gradient boosting classifier\")\n",
    "\n",
    "# grid_search = grid_search.GridSearchCV(\n",
    "#     estimator = ensemble.GradientBoostingClassifier(\n",
    "#         learning_rate=0.001,\n",
    "#         min_samples_split=40,\n",
    "#         min_samples_leaf=1,\n",
    "#         max_features=2,\n",
    "#         max_depth=12,\n",
    "#         n_estimators=70,\n",
    "#         subsample=0.75,\n",
    "#         random_state=10), \n",
    "#     param_grid = {'n_estimators':[140, 280, 560, 1120, 4480]},\n",
    "#     scoring='roc_auc',\n",
    "#     n_jobs=4,\n",
    "#     iid=False,\n",
    "#     cv=10)\n",
    "\n",
    "# grid_search.fit(features, target)\n",
    "# print(grid_search.grid_scores_, grid_search.best_params_, grid_search.best_score_)\n",
    "\n",
    "gbm = ensemble.GradientBoostingClassifier(\n",
    "    learning_rate = 0.005,\n",
    "    min_samples_split=40,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=2,\n",
    "    max_depth=12,\n",
    "    n_estimators=1500,\n",
    "    subsample=0.75,\n",
    "    random_state=1)\n",
    "gbm = gbm.fit(features, target)\n",
    "\n",
    "print(gbm.feature_importances_)\n",
    "print(gbm.score(features, target))\n",
    "\n",
    "# scores = model_selection.cross_val_score(gbm, features, target, scoring='accuracy', cv=20)\n",
    "# print scores\n",
    "# print scores.mean()\n",
    "\n",
    "test_features = test[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\"]].values\n",
    "prediction_gbm = gbm.predict(test_features)\n",
    "write_prediction(prediction_gbm, \"gbm.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
